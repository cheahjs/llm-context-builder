name: CI

on:
  push:
    branches:
      - main

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        run: curl -LsSf https://astral.sh/uv/0.3.3/install.sh | sh

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"

      - name: Install the project
        run: uv sync --all-extras --dev

      - name: Run linter
        run: |
          uv run ruff check

      - name: Verify llm-context-builder help command
        run: uv run llm-context-builder --help

      - name: Test llm-context-builder with default tokenizer
        run: uv run llm-context-builder file .

      - name: Test llm-context-builder with naive tokenizer
        run: uv run llm-context-builder --tokenizer naive file .

      - name: Test llm-context-builder with tiktoken tokenizer
        run: uv run llm-context-builder --tokenizer tiktoken file .

      - name: Test llm-context-builder with gemini tokenizer
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: uv run llm-context-builder --tokenizer gemini --tokenizer-model gemini-1.5-flash-latest file .

      - name: Test llm-context-builder with transformers tokenizer
        run: uv run llm-context-builder --tokenizer transformers --tokenizer-model Xenova/Meta-Llama-3.1-Tokenizer file .
